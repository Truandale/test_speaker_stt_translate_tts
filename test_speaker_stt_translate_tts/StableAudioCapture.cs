using NAudio.CoreAudioApi;
using NAudio.Wave;
using NAudio.MediaFoundation;
using System.Buffers;
using System.Threading.Channels;
using System.Runtime.InteropServices;

namespace test_speaker_stt_translate_tts
{
    /// <summary>
    /// –°—Ç–∞–±–∏–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –∑–∞—Ö–≤–∞—Ç–∞ –∞—É–¥–∏–æ —Å –≥–æ—Ä—è—á–∏–º –ø–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ–º –∏ –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º–∏ GC-–ø–∞—É–∑–∞–º–∏
    /// </summary>
    public class StableAudioCapture : IDisposable
    {
        #region –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
        
        // üîß –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ - –º–æ–∂–Ω–æ –º–µ–Ω—è—Ç—å –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        private const bool ENABLE_DIAGNOSTIC_STUBS = false;     // –í–∫–ª—é—á–∏—Ç—å —Ç–µ—Å—Ç–æ–≤—ã–µ –∑–∞–≥–ª—É—à–∫–∏
        private const bool ENABLE_STATS_LOGGING = true;         // –ü–æ–∫–∞–∑—ã–≤–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –æ–±—Ä–∞–±–æ—Ç–∫–∏
        private const double STATS_INTERVAL_SECONDS = 5.0;      // –ò–Ω—Ç–µ—Ä–≤–∞–ª –≤—ã–≤–æ–¥–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        
        #endregion
        
        #region MMCSS –∏ Power Management –¥–ª—è –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞ –ø–æ—Ç–æ–∫–æ–≤
        
        [DllImport("avrt.dll", CharSet = CharSet.Unicode)]
        private static extern IntPtr AvSetMmThreadCharacteristics(string taskName, out int taskIndex);
        
        [DllImport("avrt.dll")]
        private static extern bool AvRevertMmThreadCharacteristics(IntPtr handle);
        
        [DllImport("kernel32.dll")]
        private static extern uint SetThreadExecutionState(uint esFlags);
        
        private const uint ES_CONTINUOUS = 0x80000000;
        private const uint ES_SYSTEM_REQUIRED = 0x00000001;
        private const uint ES_AWAYMODE_REQUIRED = 0x00000040;
        
        #endregion

        #region Private Fields
        
        private WasapiLoopbackCapture? _capture;
        private MMDeviceEnumerator? _deviceEnumerator;
        private DeviceNotificationClient? _deviceNotificationClient;
        private bool _mediaFoundationInitialized = false;
        
        // Event-driven –∫–∞–Ω–∞–ª—ã —Å bounded capacity –¥–ª—è backpressure
        private readonly Channel<byte[]> _rawAudioChannel;
        private readonly Channel<float[]> _normalizedAudioChannel;
        private readonly Channel<string> _sttResultChannel;
        private readonly Channel<string> _translationChannel;
        
        // ArrayPool –¥–ª—è –º–∏–Ω–∏–º–∏–∑–∞—Ü–∏–∏ GC-–ø–∞—É–∑
        private readonly ArrayPool<byte> _bytePool = ArrayPool<byte>.Shared;
        private readonly ArrayPool<float> _floatPool = ArrayPool<float>.Shared;
        
        // Cancellation –∏ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        private readonly CancellationTokenSource _cancellationTokenSource = new();
        private bool _isDisposed = false;
        private bool _isCapturing = false;
        
        // MMCSS handles –¥–ª—è –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–≤
        private IntPtr _captureThreadHandle = IntPtr.Zero;
        private IntPtr _normalizeThreadHandle = IntPtr.Zero;
        
        // –†–∞–±–æ—á–∏–µ –∑–∞–¥–∞—á–∏
        private Task? _normalizeTask;
        private Task? _sttTask;
        private Task? _translationTask;
        
        // –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        private const int CHANNEL_CAPACITY = 64;
        private const int TARGET_SAMPLE_RATE = 16000;
        private const int TARGET_CHANNELS = 1;
        private const int AUDIO_LATENCY_MS = 30;
        
        #endregion

        #region Events
        
        public event Action<string>? OnTextRecognized;
        public event Action<string>? OnTextTranslated;
        public event Action<string>? OnError;
        public event Action<string>? OnStatusChanged;
        
        #endregion

        public StableAudioCapture()
        {
            // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è MediaFoundation –¥–ª—è —Ä–µ—Å–µ–º–ø–ª–∏–Ω–≥–∞
            if (!_mediaFoundationInitialized)
            {
                MediaFoundationApi.Startup();
                _mediaFoundationInitialized = true;
            }
            
            // –°–æ–∑–¥–∞–Ω–∏–µ bounded channels —Å backpressure
            var channelOptions = new BoundedChannelOptions(CHANNEL_CAPACITY)
            {
                SingleWriter = true,
                SingleReader = false,
                FullMode = BoundedChannelFullMode.DropOldest // –î—Ä–æ–ø–∞–µ–º —Å—Ç–∞—Ä—ã–µ –ø—Ä–∏ –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∏–∏
            };
            
            _rawAudioChannel = Channel.CreateBounded<byte[]>(channelOptions);
            _normalizedAudioChannel = Channel.CreateBounded<float[]>(channelOptions);
            _sttResultChannel = Channel.CreateBounded<string>(channelOptions);
            _translationChannel = Channel.CreateBounded<string>(channelOptions);
            
            // –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏–µ —Å–Ω–∞ —Å–∏—Å—Ç–µ–º—ã –≤–æ –≤—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã
            SetThreadExecutionState(ES_CONTINUOUS | ES_SYSTEM_REQUIRED | ES_AWAYMODE_REQUIRED);
        }

        #region Device Notification Client (Simplified)
        
        private class DeviceNotificationClient
        {
            public Action? OnDefaultChanged { get; set; }
            
            // Simplified device monitoring - can be enhanced later
            public void StartMonitoring()
            {
                // TODO: Implement device monitoring if needed
                // For now, just a placeholder
            }
            
            public void StopMonitoring()
            {
                // TODO: Implement device monitoring cleanup
            }
        }
        
        #endregion

        #region Public Methods
        
        public async Task StartCaptureAsync()
        {
            if (_isCapturing || _isDisposed)
                return;
                
            try
            {
                OnStatusChanged?.Invoke("üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ç–∞–±–∏–ª—å–Ω–æ–≥–æ –∞—É–¥–∏–æ-–∑–∞—Ö–≤–∞—Ç–∞...");
                
                // –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≥–æ—Ä—è—á–µ–≥–æ –ø–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤
                await SetupDeviceMonitoringAsync();
                
                // –ó–∞–ø—É—Å–∫ –∑–∞—Ö–≤–∞—Ç–∞
                await StartAudioCaptureAsync();
                
                // –ó–∞–ø—É—Å–∫ –∫–æ–Ω–≤–µ–π–µ—Ä–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏
                StartProcessingPipeline();
                
                _isCapturing = true;
                OnStatusChanged?.Invoke("‚úÖ –°—Ç–∞–±–∏–ª—å–Ω—ã–π –∞—É–¥–∏–æ-–∑–∞—Ö–≤–∞—Ç –∞–∫—Ç–∏–≤–µ–Ω");
            }
            catch (Exception ex)
            {
                OnError?.Invoke($"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –∑–∞—Ö–≤–∞—Ç–∞: {ex.Message}");
                await StopCaptureAsync();
            }
        }
        
        public async Task StopCaptureAsync()
        {
            if (!_isCapturing)
                return;
                
            OnStatusChanged?.Invoke("‚èπÔ∏è –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∞—É–¥–∏–æ-–∑–∞—Ö–≤–∞—Ç–∞...");
            
            _isCapturing = false;
            
            // –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞—Ö–≤–∞—Ç–∞
            await StopAudioCaptureAsync();
            
            // –ó–∞–∫—Ä—ã—Ç–∏–µ –∫–∞–Ω–∞–ª–æ–≤
            _rawAudioChannel.Writer.TryComplete();
            _normalizedAudioChannel.Writer.TryComplete();
            _sttResultChannel.Writer.TryComplete();
            _translationChannel.Writer.TryComplete();
            
            // –û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∑–∞–¥–∞—á
            await Task.WhenAll(
                _normalizeTask ?? Task.CompletedTask,
                _sttTask ?? Task.CompletedTask,
                _translationTask ?? Task.CompletedTask
            );
            
            OnStatusChanged?.Invoke("‚úÖ –ê—É–¥–∏–æ-–∑–∞—Ö–≤–∞—Ç –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω");
        }
        
        #endregion

        #region Private Methods - Device Management
        
        private async Task SetupDeviceMonitoringAsync()
        {
            _deviceEnumerator = new MMDeviceEnumerator();
            _deviceNotificationClient = new DeviceNotificationClient
            {
                OnDefaultChanged = async () => await RestartCaptureSafeAsync()
            };
            
            // Simplified monitoring setup
            _deviceNotificationClient.StartMonitoring();
            
            // TODO: Implement proper device change detection
            // For now, monitoring is placeholder
        }
        
        private async Task RestartCaptureSafeAsync()
        {
            OnStatusChanged?.Invoke("üîÑ –ü–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –Ω–æ–≤–æ–º—É –∞—É–¥–∏–æ-—É—Å—Ç—Ä–æ–π—Å—Ç–≤—É...");
            
            try
            {
                // –û—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ç–µ–∫—É—â–µ–≥–æ –∑–∞—Ö–≤–∞—Ç–∞ (–±–µ–∑ –∑–∞–∫—Ä—ã—Ç–∏—è –∫–∞–Ω–∞–ª–æ–≤)
                await StopAudioCaptureAsync();
                
                // –ü–∞—É–∑–∞ –¥–ª—è —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏–∏
                await Task.Delay(100);
                
                // –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ —Å –Ω–æ–≤—ã–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ–º
                await StartAudioCaptureAsync();
                
                OnStatusChanged?.Invoke("‚úÖ –£—Å–ø–µ—à–Ω–æ –ø–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–µ–Ω –∫ –Ω–æ–≤–æ–º—É —É—Å—Ç—Ä–æ–π—Å—Ç–≤—É");
            }
            catch (Exception ex)
            {
                OnError?.Invoke($"‚ùå –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: {ex.Message}");
            }
        }
        
        #endregion

        #region Private Methods - Audio Capture
        
        private async Task StartAudioCaptureAsync()
        {
            if (_deviceEnumerator == null)
                throw new InvalidOperationException("Device enumerator not initialized");
                
            // –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–µ—Ñ–æ–ª—Ç–Ω–æ–≥–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è
            var defaultDevice = _deviceEnumerator.GetDefaultAudioEndpoint(DataFlow.Render, Role.Multimedia);
            
            // –°–æ–∑–¥–∞–Ω–∏–µ –∑–∞—Ö–≤–∞—Ç–∞ —Å –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –ª–∞—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å—é
            _capture = new WasapiLoopbackCapture(defaultDevice);
            
            // Event-driven –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å ArrayPool
            _capture.DataAvailable += OnDataAvailable;
            _capture.RecordingStopped += OnRecordingStopped;
            
            OnStatusChanged?.Invoke($"üéß –ó–∞—Ö–≤–∞—Ç: {defaultDevice.FriendlyName} ({_capture.WaveFormat})");
            
            // –ó–∞–ø—É—Å–∫ –∑–∞–ø–∏—Å–∏
            _capture.StartRecording();
        }
        
        private async Task StopAudioCaptureAsync()
        {
            if (_capture != null)
            {
                try
                {
                    if (_capture.CaptureState == CaptureState.Capturing)
                    {
                        _capture.StopRecording();
                    }
                    
                    // –û—Ç–ø–∏—Å–∫–∞ –æ—Ç —Å–æ–±—ã—Ç–∏–π
                    _capture.DataAvailable -= OnDataAvailable;
                    _capture.RecordingStopped -= OnRecordingStopped;
                    
                    _capture.Dispose();
                    _capture = null;
                }
                catch (Exception ex)
                {
                    OnError?.Invoke($"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –∑–∞—Ö–≤–∞—Ç–∞: {ex.Message}");
                }
            }
            
            // –û—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ MMCSS handles
            if (_captureThreadHandle != IntPtr.Zero)
            {
                AvRevertMmThreadCharacteristics(_captureThreadHandle);
                _captureThreadHandle = IntPtr.Zero;
            }
        }
        
        private void OnDataAvailable(object? sender, WaveInEventArgs e)
        {
            if (e.BytesRecorded <= 0 || _cancellationTokenSource.Token.IsCancellationRequested)
                return;
                
            // MMCSS –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –¥–ª—è capture thread (—Ç–æ–ª—å–∫–æ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –≤—ã–∑–æ–≤–µ)
            if (_captureThreadHandle == IntPtr.Zero)
            {
                _captureThreadHandle = AvSetMmThreadCharacteristics("Audio", out _);
                Thread.CurrentThread.Priority = ThreadPriority.Highest;
            }
            
            // –ê—Ä–µ–Ω–¥–∞ –±—É—Ñ–µ—Ä–∞ –∏–∑ pool (–º–∏–Ω–∏–º–∏–∑–∞—Ü–∏—è GC)
            var buffer = _bytePool.Rent(e.BytesRecorded);
            
            try
            {
                // –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
                Buffer.BlockCopy(e.Buffer, 0, buffer, 0, e.BytesRecorded);
                
                // –û—Ç–ø—Ä–∞–≤–∫–∞ –≤ –∫–∞–Ω–∞–ª —Å backpressure
                if (!_rawAudioChannel.Writer.TryWrite(buffer))
                {
                    // –ö–∞–Ω–∞–ª –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω - –¥—Ä–æ–ø–∞–µ–º –∫–∞–¥—Ä, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –≤ pool
                    _bytePool.Return(buffer);
                }
            }
            catch
            {
                // –ü—Ä–∏ –ª—é–±–æ–π –æ—à–∏–±–∫–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –±—É—Ñ–µ—Ä –≤ pool
                _bytePool.Return(buffer);
            }
        }
        
        private void OnRecordingStopped(object? sender, StoppedEventArgs e)
        {
            if (e.Exception != null)
            {
                OnError?.Invoke($"‚ùå –ó–∞—Ö–≤–∞—Ç –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω —Å –æ—à–∏–±–∫–æ–π: {e.Exception.Message}");
                _rawAudioChannel.Writer.TryComplete(e.Exception);
            }
        }
        
        #endregion

        #region Private Methods - Processing Pipeline
        
        private void StartProcessingPipeline()
        {
            var ct = _cancellationTokenSource.Token;
            
            // –ó–∞–¥–∞—á–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏: raw PCM ‚Üí 16kHz mono float
            _normalizeTask = Task.Run(async () => await NormalizeAudioLoop(ct), ct);
            
            // –ó–∞–¥–∞—á–∞ STT: normalized audio ‚Üí text
            _sttTask = Task.Run(async () => await SttProcessingLoop(ct), ct);
            
            // –ó–∞–¥–∞—á–∞ –ø–µ—Ä–µ–≤–æ–¥–∞: text ‚Üí translated text
            _translationTask = Task.Run(async () => await TranslationLoop(ct), ct);
        }
        
        private async Task NormalizeAudioLoop(CancellationToken ct)
        {
            // MMCSS –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –¥–ª—è normalize thread
            _normalizeThreadHandle = AvSetMmThreadCharacteristics("Audio", out _);
            Thread.CurrentThread.Priority = ThreadPriority.AboveNormal;
            
            WaveFormat? sourceFormat = null;
            BufferedWaveProvider? provider = null;
            MediaFoundationResampler? resampler = null;
            
            try
            {
                await foreach (var rawBuffer in _rawAudioChannel.Reader.ReadAllAsync(ct))
                {
                    try
                    {
                        // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∫–∞–¥—Ä–µ
                        if (provider == null && _capture != null)
                        {
                            sourceFormat = _capture.WaveFormat;
                            provider = new BufferedWaveProvider(sourceFormat)
                            {
                                DiscardOnBufferOverflow = true,
                                BufferDuration = TimeSpan.FromSeconds(3)
                            };
                            
                            var targetFormat = WaveFormat.CreateIeeeFloatWaveFormat(TARGET_SAMPLE_RATE, TARGET_CHANNELS);
                            resampler = new MediaFoundationResampler(provider, targetFormat)
                            {
                                ResamplerQuality = 60 // –í—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ
                            };
                            
                            OnStatusChanged?.Invoke($"üîÑ –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è: {sourceFormat} ‚Üí {targetFormat}");
                        }
                        
                        if (provider != null && resampler != null)
                        {
                            // –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤ –±—É—Ñ–µ—Ä
                            provider.AddSamples(rawBuffer, 0, rawBuffer.Length);
                            
                            // –ß—Ç–µ–Ω–∏–µ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                            await ProcessNormalizedAudio(resampler, ct);
                        }
                    }
                    finally
                    {
                        // –í–æ–∑–≤—Ä–∞—Ç –±—É—Ñ–µ—Ä–∞ –≤ pool
                        _bytePool.Return(rawBuffer);
                    }
                }
            }
            catch (OperationCanceledException)
            {
                // –ù–æ—Ä–º–∞–ª—å–Ω–∞—è –æ—Ç–º–µ–Ω–∞
            }
            catch (Exception ex)
            {
                OnError?.Invoke($"‚ùå –û—à–∏–±–∫–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏: {ex.Message}");
            }
            finally
            {
                resampler?.Dispose();
                provider?.ClearBuffer();
                
                if (_normalizeThreadHandle != IntPtr.Zero)
                {
                    AvRevertMmThreadCharacteristics(_normalizeThreadHandle);
                    _normalizeThreadHandle = IntPtr.Zero;
                }
            }
        }
        
        private async Task ProcessNormalizedAudio(MediaFoundationResampler resampler, CancellationToken ct)
        {
            var bytesPerFrame = sizeof(float) * TARGET_CHANNELS;
            var maxFramesPerRead = TARGET_SAMPLE_RATE; // 1 —Å–µ–∫—É–Ω–¥–∞ –º–∞–∫—Å–∏–º—É–º
            var byteBuffer = _bytePool.Rent(maxFramesPerRead * bytesPerFrame);
            
            try
            {
                int bytesRead = resampler.Read(byteBuffer, 0, byteBuffer.Length);
                if (bytesRead <= 0)
                    return;
                    
                var frameCount = bytesRead / bytesPerFrame;
                var floatBuffer = _floatPool.Rent(frameCount);
                
                try
                {
                    // –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è byte[] ‚Üí float[]
                    Buffer.BlockCopy(byteBuffer, 0, floatBuffer, 0, bytesRead);
                    
                    // –û–±—Ä–∞–±–æ—Ç–∫–∞ stereo ‚Üí mono –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                    var processedAudio = ProcessAudioChannels(floatBuffer.AsSpan(0, frameCount));
                    
                    // üîá –ê–£–î–ò–û-–ì–ï–ô–¢–ò–ù–ì: –ü—Ä–æ–≤–µ—Ä–∫–∞ RMS —É—Ä–æ–≤–Ω—è –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —Ç–∏—à–∏–Ω—ã
                    var rms = CalculateRMS(processedAudio);
                    const float SILENCE_THRESHOLD = 0.001f; // –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ –≥—Ä–æ–º–∫–æ—Å—Ç–∏
                    
                    if (rms < SILENCE_THRESHOLD)
                    {
                        // –¢–∏—à–∏–Ω–∞ - –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ STT, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –±—É—Ñ–µ—Ä
                        _floatPool.Return(processedAudio);
                        return;
                    }
                    
                    // –û—Ç–ø—Ä–∞–≤–∫–∞ –≤ STT –∫–∞–Ω–∞–ª
                    if (!_normalizedAudioChannel.Writer.TryWrite(processedAudio))
                    {
                        // Backpressure - –¥—Ä–æ–ø–∞–µ–º —Å–µ–≥–º–µ–Ω—Ç
                        _floatPool.Return(processedAudio);
                    }
                }
                catch
                {
                    _floatPool.Return(floatBuffer);
                    throw;
                }
            }
            finally
            {
                _bytePool.Return(byteBuffer);
            }
        }
        
        private float[] ProcessAudioChannels(ReadOnlySpan<float> source)
        {
            if (_capture?.WaveFormat.Channels == 1)
            {
                // –£–∂–µ mono - –ø—Ä–æ—Å—Ç–æ –∫–æ–ø–∏—Ä—É–µ–º
                var result = _floatPool.Rent(source.Length);
                source.CopyTo(result);
                return result;
            }
            else if (_capture?.WaveFormat.Channels == 2)
            {
                // Stereo ‚Üí mono downmix
                var monoFrames = source.Length / 2;
                var result = _floatPool.Rent(monoFrames);
                StereoToMono(source, result.AsSpan(0, monoFrames));
                return result;
            }
            else
            {
                // –ú–Ω–æ–≥–æ–∫–∞–Ω–∞–ª—å–Ω—ã–π ‚Üí mono (–±–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π –∫–∞–Ω–∞–ª)
                var channels = _capture?.WaveFormat.Channels ?? 1;
                var monoFrames = source.Length / channels;
                var result = _floatPool.Rent(monoFrames);
                
                for (int i = 0; i < monoFrames; i++)
                {
                    result[i] = source[i * channels];
                }
                
                return result;
            }
        }
        
        private static void StereoToMono(ReadOnlySpan<float> stereo, Span<float> mono)
        {
            int sourceIndex = 0;
            for (int i = 0; i < mono.Length; i++, sourceIndex += 2)
            {
                mono[i] = 0.5f * (stereo[sourceIndex] + stereo[sourceIndex + 1]);
            }
        }
        
        private async Task SttProcessingLoop(CancellationToken ct)
        {
            Thread.CurrentThread.Priority = ThreadPriority.AboveNormal;
            
            // üîß –°—á–µ—Ç—á–∏–∫–∏ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ (–Ω–µ —Å–ø–∞–º—è—Ç –ª–æ–≥–∏)
            var processedSegments = 0;
            var lastStatsTime = DateTime.Now;
            
            try
            {
                await foreach (var audioSegment in _normalizedAudioChannel.Reader.ReadAllAsync(ct))
                {
                    try
                    {
                        // TODO: –ó–¥–µ—Å—å –±—É–¥–µ—Ç –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Whisper
                        // var recognizedText = await WhisperRecognizeAsync(audioSegment, ct);
                        
                        await Task.Delay(10, ct);
                        processedSegments++;
                        
                        // ÔøΩ –£–ú–ù–ê–Ø –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê: –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ä–∞–∑ –≤ 5 —Å–µ–∫—É–Ω–¥
                        var now = DateTime.Now;
                        if ((now - lastStatsTime).TotalSeconds >= 5.0)
                        {
                            OnStatusChanged?.Invoke($"üìä STT: –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {processedSegments} —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –∑–∞ {(now - lastStatsTime).TotalSeconds:F1}—Å");
                            processedSegments = 0;
                            lastStatsTime = now;
                        }
                        
                        // üß™ –¢–ï–°–¢–û–í–ê–Ø –ó–ê–ì–õ–£–®–ö–ê: –ú–æ–∂–Ω–æ –≤–∫–ª—é—á–∏—Ç—å –¥–ª—è —Ç–µ—Å—Ç–æ–≤ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π
                        string? recognizedText = null;
                        
                        // –†–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –ø–∞–π–ø–ª–∞–π–Ω–∞:
                        // if (audioSegment.Length > 4000) // –¢–æ–ª—å–∫–æ –¥–ª—è "–¥–ª–∏–Ω–Ω—ã—Ö" —Å–µ–≥–º–µ–Ω—Ç–æ–≤
                        //     recognizedText = $"[TEST] Audio {audioSegment.Length} samples, RMS: {CalculateRMS(audioSegment):F4}";
                        
                        if (!string.IsNullOrWhiteSpace(recognizedText))
                        {
                            OnTextRecognized?.Invoke(recognizedText);
                            await _sttResultChannel.Writer.WriteAsync(recognizedText, ct);
                        }
                    }
                    finally
                    {
                        _floatPool.Return(audioSegment);
                    }
                }
            }
            catch (OperationCanceledException)
            {
                // –ù–æ—Ä–º–∞–ª—å–Ω–∞—è –æ—Ç–º–µ–Ω–∞
            }
            catch (Exception ex)
            {
                OnError?.Invoke($"‚ùå –û—à–∏–±–∫–∞ STT: {ex.Message}");
            }
        }
        
        private async Task TranslationLoop(CancellationToken ct)
        {
            Thread.CurrentThread.Priority = ThreadPriority.Normal;
            
            try
            {
                await foreach (var text in _sttResultChannel.Reader.ReadAllAsync(ct))
                {
                    try
                    {
                        // TODO: –ó–¥–µ—Å—å –±—É–¥–µ—Ç –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫–æ–º
                        // var translatedText = await TranslateAsync(text, "ru", "en", ct);
                        
                        // –í—Ä–µ–º–µ–Ω–Ω–∞—è –∑–∞–≥–ª—É—à–∫–∞
                        await Task.Delay(50, ct);
                        var translatedText = $"[TRANSLATED] {text}";
                        
                        OnTextTranslated?.Invoke(translatedText);
                        await _translationChannel.Writer.WriteAsync(translatedText, ct);
                    }
                    catch (Exception ex)
                    {
                        OnError?.Invoke($"‚ùå –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞: {ex.Message}");
                    }
                }
            }
            catch (OperationCanceledException)
            {
                // –ù–æ—Ä–º–∞–ª—å–Ω–∞—è –æ—Ç–º–µ–Ω–∞
            }
        }
        
        /// <summary>
        /// –í—ã—á–∏—Å–ª—è–µ—Ç RMS (Root Mean Square) —É—Ä–æ–≤–µ–Ω—å –≥—Ä–æ–º–∫–æ—Å—Ç–∏ –∞—É–¥–∏–æ —Å–∏–≥–Ω–∞–ª–∞
        /// </summary>
        /// <param name="audioData">–ê—É–¥–∏–æ –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ float</param>
        /// <returns>RMS –∑–Ω–∞—á–µ–Ω–∏–µ (0.0 - —Ç–∏—à–∏–Ω–∞, 1.0 - –º–∞–∫—Å–∏–º—É–º)</returns>
        private static float CalculateRMS(ReadOnlySpan<float> audioData)
        {
            if (audioData.Length == 0)
                return 0.0f;
                
            double sum = 0.0;
            for (int i = 0; i < audioData.Length; i++)
            {
                var sample = audioData[i];
                sum += sample * sample;
            }
            
            return (float)Math.Sqrt(sum / audioData.Length);
        }
        
        #endregion

        #region IDisposable
        
        public void Dispose()
        {
            if (_isDisposed)
                return;
                
            _isDisposed = true;
            
            // –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞—Ö–≤–∞—Ç–∞
            StopCaptureAsync().GetAwaiter().GetResult();
            
            // –û—Ç–º–µ–Ω–∞ –≤—Å–µ—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
            _cancellationTokenSource.Cancel();
            
            // –û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤
            _deviceEnumerator?.Dispose();
            _deviceNotificationClient?.StopMonitoring();
            _capture?.Dispose();
            
            _cancellationTokenSource.Dispose();
            
            // –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ power state
            SetThreadExecutionState(ES_CONTINUOUS);
            
            // MediaFoundation cleanup
            if (_mediaFoundationInitialized)
            {
                MediaFoundationApi.Shutdown();
                _mediaFoundationInitialized = false;
            }
        }
        
        #endregion
    }
}