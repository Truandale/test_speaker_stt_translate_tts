using NAudio.CoreAudioApi;
using NAudio.Wave;
using Whisper.net;
using System.Speech.Synthesis;
using RestSharp;
using Newtonsoft.Json;
using Newtonsoft.Json.Linq;
using System.Text;
using System.Text.RegularExpressions;
using System.Diagnostics;

namespace test_speaker_stt_translate_tts
{
    public partial class Form1 : Form
    {
        #region Private Fields
        
        private WasapiLoopbackCapture? wasapiCapture;
        private List<byte> audioBuffer = new();
        private bool isCapturing = false;
        private bool isCollectingAudio = false;
        private DateTime lastVoiceActivity = DateTime.Now;
        private DateTime recordingStartTime = DateTime.Now;
        private float voiceThreshold = 0.05f; // –ü–æ–≤—ã—Å–∏–º –ø–æ—Ä–æ–≥ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏
        private int silenceDurationMs = 1000; // –°–æ–∫—Ä–∞—Ç–∏–º –¥–æ 1 —Å–µ–∫
        private int maxRecordingMs = 5000; // –ú–∞–∫—Å–∏–º—É–º 5 —Å–µ–∫—É–Ω–¥ –∑–∞–ø–∏—Å–∏ (—Å–æ–∫—Ä–∞—Ç–∏–ª–∏ —Å 10 —Å–µ–∫)
        private System.Windows.Forms.Timer? audioLevelTimer;
        private float currentAudioLevel = 0f;
        
        // STT & Translation
        private static string WhisperModelPath => Path.Combine(Application.StartupPath, "models", "whisper", "ggml-small.bin");
        private SpeechSynthesizer? speechSynthesizer;
        private RestClient? googleTranslateClient;
        
        // Language mappings
        private readonly Dictionary<string, string> languageCodes = new()
        {
            { "–†—É—Å—Å–∫–∏–π", "ru" },
            { "–ê–Ω–≥–ª–∏–π—Å–∫–∏–π", "en" },
            { "–ù–µ–º–µ—Ü–∫–∏–π", "de" },
            { "–§—Ä–∞–Ω—Ü—É–∑—Å–∫–∏–π", "fr" },
            { "–ò—Å–ø–∞–Ω—Å–∫–∏–π", "es" },
            { "–ò—Ç–∞–ª—å—è–Ω—Å–∫–∏–π", "it" },
            { "–Ø–ø–æ–Ω—Å–∫–∏–π", "ja" },
            { "–ö–∏—Ç–∞–π—Å–∫–∏–π", "zh" }
        };

        #endregion

        #region Constructor & Initialization

        public Form1()
        {
            InitializeComponent();
            InitializeApplication();
        }

        private void InitializeApplication()
        {
            LogMessage("üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è...");
            
            // Check Whisper model first
            if (!CheckWhisperModel())
            {
                MessageBox.Show(
                    $"‚ùå Whisper –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!\n\n" +
                    $"–û–∂–∏–¥–∞–µ–º—ã–π –ø—É—Ç—å:\n{WhisperModelPath}\n\n" +
                    $"–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ –º–æ–¥–µ–ª—å ggml-small.bin –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –ø–æ —É–∫–∞–∑–∞–Ω–Ω–æ–º—É –ø—É—Ç–∏.",
                    "–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏",
                    MessageBoxButtons.OK,
                    MessageBoxIcon.Error);
            }
            
            // Initialize components
            InitializeAudioDevices();
            InitializeLanguages();
            InitializeTTS();
            InitializeTranslation();
            InitializeTimer();
            
            // Set default threshold
            voiceThreshold = (float)numThreshold.Value;
            numThreshold.ValueChanged += (s, e) => voiceThreshold = (float)numThreshold.Value;
            
            LogMessage("‚úÖ –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –≥–æ—Ç–æ–≤–æ –∫ —Ä–∞–±–æ—Ç–µ");
        }

        private bool CheckWhisperModel()
        {
            try
            {
                if (File.Exists(WhisperModelPath))
                {
                    var fileInfo = new FileInfo(WhisperModelPath);
                    LogMessage($"‚úÖ Whisper –º–æ–¥–µ–ª—å –Ω–∞–π–¥–µ–Ω–∞: {fileInfo.Length / 1024 / 1024:F1} MB");
                    return true;
                }
                else
                {
                    LogMessage($"‚ùå Whisper –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {WhisperModelPath}");
                    return false;
                }
            }
            catch (Exception ex)
            {
                LogMessage($"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ Whisper –º–æ–¥–µ–ª–∏: {ex.Message}");
                return false;
            }
        }

        private void InitializeAudioDevices()
        {
            LogMessage("üîç –ü–æ–∏—Å–∫ –∞—É–¥–∏–æ—É—Å—Ç—Ä–æ–π—Å—Ç–≤...");
            
            cbSpeakerDevices.Items.Clear();
            
            var enumerator = new MMDeviceEnumerator();
            var devices = enumerator.EnumerateAudioEndPoints(DataFlow.Render, DeviceState.Active);
            
            foreach (var device in devices)
            {
                string deviceInfo = $"{device.FriendlyName}";
                cbSpeakerDevices.Items.Add(new AudioDevice 
                { 
                    Name = deviceInfo, 
                    Device = device 
                });
                LogMessage($"   üìª {deviceInfo}");
            }
            
            if (cbSpeakerDevices.Items.Count > 0)
            {
                cbSpeakerDevices.SelectedIndex = 0;
                LogMessage($"‚úÖ –ù–∞–π–¥–µ–Ω–æ {cbSpeakerDevices.Items.Count} –∞—É–¥–∏–æ—É—Å—Ç—Ä–æ–π—Å—Ç–≤");
            }
            else
            {
                LogMessage("‚ùå –ê—É–¥–∏–æ—É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!");
            }
        }

        private void InitializeLanguages()
        {
            cbSourceLang.Items.AddRange(languageCodes.Keys.ToArray());
            cbTargetLang.Items.AddRange(languageCodes.Keys.ToArray());
            
            cbSourceLang.SelectedItem = "–ê–Ω–≥–ª–∏–π—Å–∫–∏–π";
            cbTargetLang.SelectedItem = "–†—É—Å—Å–∫–∏–π";
        }

        private void InitializeTTS()
        {
            try
            {
                speechSynthesizer = new SpeechSynthesizer();
                speechSynthesizer.Volume = 100;
                speechSynthesizer.Rate = 0;
                LogMessage("‚úÖ TTS –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω");
            }
            catch (Exception ex)
            {
                LogMessage($"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ TTS: {ex.Message}");
            }
        }

        private void InitializeTranslation()
        {
            try
            {
                googleTranslateClient = new RestClient("https://translate.googleapis.com");
                LogMessage("‚úÖ Google Translate –∫–ª–∏–µ–Ω—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω");
            }
            catch (Exception ex)
            {
                LogMessage($"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫–∞: {ex.Message}");
            }
        }

        private void InitializeTimer()
        {
            audioLevelTimer = new System.Windows.Forms.Timer();
            audioLevelTimer.Interval = 100; // Update every 100ms
            audioLevelTimer.Tick += AudioLevelTimer_Tick;
        }

        #endregion

        #region Audio Capture

        private void btnStartCapture_Click(object sender, EventArgs e)
        {
            StartAudioCapture();
        }

        private void btnStopCapture_Click(object sender, EventArgs e)
        {
            StopAudioCapture();
        }

        private void StartAudioCapture()
        {
            try
            {
                if (cbSpeakerDevices.SelectedItem is not AudioDevice selectedDevice)
                {
                    LogMessage("‚ùå –í—ã–±–µ—Ä–∏—Ç–µ –∞—É–¥–∏–æ—É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ!");
                    return;
                }

                if (!File.Exists(WhisperModelPath))
                {
                    LogMessage($"‚ùå Whisper –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {WhisperModelPath}");
                    return;
                }

                LogMessage("üéß –ó–∞–ø—É—Å–∫ –∑–∞—Ö–≤–∞—Ç–∞ –∞—É–¥–∏–æ...");
                
                // Initialize WASAPI Loopback Capture
                wasapiCapture = new WasapiLoopbackCapture(selectedDevice.Device);
                wasapiCapture.DataAvailable += OnAudioDataAvailable;
                wasapiCapture.RecordingStopped += OnRecordingStopped;
                
                // Start capture
                wasapiCapture.StartRecording();
                audioLevelTimer?.Start();
                
                isCapturing = true;
                audioBuffer.Clear();
                
                // Update UI
                btnStartCapture.Enabled = false;
                btnStopCapture.Enabled = true;
                lblStatus.Text = "üéß –ó–∞—Ö–≤–∞—Ç –∞–∫—Ç–∏–≤–µ–Ω";
                lblStatus.ForeColor = Color.Green;
                txtRecognizedText.Text = "üîá –û–∂–∏–¥–∞–Ω–∏–µ —Ä–µ—á–∏...";
                txtTranslatedText.Text = "üîá –û–∂–∏–¥–∞–Ω–∏–µ –ø–µ—Ä–µ–≤–æ–¥–∞...";
                
                LogMessage($"‚úÖ –ó–∞—Ö–≤–∞—Ç –∑–∞–ø—É—â–µ–Ω: {selectedDevice.Name}");
                LogMessage($"üéöÔ∏è –ü–æ—Ä–æ–≥ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏: {voiceThreshold:F3}");
            }
            catch (Exception ex)
            {
                LogMessage($"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –∑–∞—Ö–≤–∞—Ç–∞: {ex.Message}");
            }
        }

        private void StopAudioCapture()
        {
            try
            {
                LogMessage("‚èπÔ∏è –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞—Ö–≤–∞—Ç–∞ –∞—É–¥–∏–æ...");
                
                isCapturing = false;
                audioLevelTimer?.Stop();
                
                wasapiCapture?.StopRecording();
                wasapiCapture?.Dispose();
                wasapiCapture = null;
                
                // Update UI
                btnStartCapture.Enabled = true;
                btnStopCapture.Enabled = false;
                lblStatus.Text = "üîá –ì–æ—Ç–æ–≤ –∫ –∑–∞—Ö–≤–∞—Ç—É";
                lblStatus.ForeColor = Color.Blue;
                progressAudioLevel.Value = 0;
                lblAudioLevel.Text = "üìä –£—Ä–æ–≤–µ–Ω—å: 0%";
                
                LogMessage("‚úÖ –ó–∞—Ö–≤–∞—Ç –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω");
            }
            catch (Exception ex)
            {
                LogMessage($"‚ùå –û—à–∏–±–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –∑–∞—Ö–≤–∞—Ç–∞: {ex.Message}");
            }
        }

        private void OnAudioDataAvailable(object? sender, WaveInEventArgs e)
        {
            if (!isCapturing) return;

            try
            {
                // Calculate audio level
                float level = CalculateAudioLevel(e.Buffer, e.BytesRecorded);
                currentAudioLevel = level;

                // Voice activity detection
                bool isVoiceDetected = level > voiceThreshold;

                if (isVoiceDetected)
                {
                    if (!isCollectingAudio)
                    {
                        isCollectingAudio = true;
                        audioBuffer.Clear();
                        recordingStartTime = DateTime.Now; // –ó–∞–ø–æ–º–Ω–∏–º –≤—Ä–µ–º—è –Ω–∞—á–∞–ª–∞ –∑–∞–ø–∏—Å–∏
                        LogMessage($"üé§ –ù–∞—á–∞—Ç –∑–∞—Ö–≤–∞—Ç —Ä–µ—á–∏ (—É—Ä–æ–≤–µ–Ω—å: {level:F3})");
                        
                        Invoke(() => {
                            txtRecognizedText.Text = "üé§ –ó–∞–ø–∏—Å—ã–≤–∞—é —Ä–µ—á—å...";
                            progressBar.Visible = true;
                        });
                    }

                    // Check for max recording time FIRST (–¥–∞–∂–µ –ø—Ä–∏ –∞–∫—Ç–∏–≤–Ω–æ–º –∑–≤—É–∫–µ)
                    var recordingDuration = DateTime.Now - recordingStartTime;
                    if (recordingDuration.TotalMilliseconds > maxRecordingMs)
                    {
                        isCollectingAudio = false;
                        LogMessage($"‚è∞ –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–ø–∏—Å–∏ (–º–∞–∫—Å–∏–º—É–º {maxRecordingMs}–º—Å –¥–æ—Å—Ç–∏–≥–Ω—É—Ç)");
                        
                        if (audioBuffer.Count > 16000)
                        {
                            LogMessage($"‚èπÔ∏è –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ (–¥–∞–Ω–Ω—ã—Ö: {audioBuffer.Count} –±–∞–π—Ç)");
                            
                            Invoke(() => {
                                txtRecognizedText.Text = "üîÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∞—É–¥–∏–æ...";
                            });
                            
                            byte[] recordedAudio = audioBuffer.ToArray();
                            _ = Task.Run(() => ProcessAudioAsync(recordedAudio));
                        }
                        
                        Invoke(() => {
                            progressBar.Visible = false;
                        });
                        return;
                    }

                    // Add audio data to buffer
                    byte[] audioData = new byte[e.BytesRecorded];
                    Array.Copy(e.Buffer, audioData, e.BytesRecorded);
                    audioBuffer.AddRange(audioData);
                    
                    lastVoiceActivity = DateTime.Now;
                }
                else if (isCollectingAudio)
                {
                    // Check for max recording time
                    var recordingDuration = DateTime.Now - recordingStartTime;
                    if (recordingDuration.TotalMilliseconds > maxRecordingMs)
                    {
                        isCollectingAudio = false;
                        LogMessage($"‚è∞ –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–ø–∏—Å–∏ (–º–∞–∫—Å–∏–º—É–º {maxRecordingMs}–º—Å –¥–æ—Å—Ç–∏–≥–Ω—É—Ç)");
                        
                        if (audioBuffer.Count > 16000)
                        {
                            LogMessage($"‚èπÔ∏è –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ (–¥–∞–Ω–Ω—ã—Ö: {audioBuffer.Count} –±–∞–π—Ç)");
                            
                            Invoke(() => {
                                txtRecognizedText.Text = "üîÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∞—É–¥–∏–æ...";
                            });
                            
                            byte[] timeoutAudio = audioBuffer.ToArray();
                            _ = Task.Run(() => ProcessAudioAsync(timeoutAudio));
                        }
                        
                        Invoke(() => {
                            progressBar.Visible = false;
                        });
                        return;
                    }
                    
                    // Check for silence timeout
                    var silenceDuration = DateTime.Now - lastVoiceActivity;
                    if (silenceDuration.TotalMilliseconds > silenceDurationMs)
                    {
                        isCollectingAudio = false;
                        
                        if (audioBuffer.Count > 16000) // Minimum audio data
                        {
                            LogMessage($"‚èπÔ∏è –ö–æ–Ω–µ—Ü —Ä–µ—á–∏ (—Ç–∏—à–∏–Ω–∞: {silenceDuration.TotalMilliseconds:F0}–º—Å, –¥–∞–Ω–Ω—ã—Ö: {audioBuffer.Count} –±–∞–π—Ç)");
                            
                            Invoke(() => {
                                txtRecognizedText.Text = "üîÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∞—É–¥–∏–æ...";
                            });
                            
                            // Process collected audio in background
                            var audioDataCopy = audioBuffer.ToArray();
                            Task.Run(() => ProcessAudioAsync(audioDataCopy));
                        }
                        
                        audioBuffer.Clear();
                    }
                }
            }
            catch (Exception ex)
            {
                LogMessage($"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ: {ex.Message}");
            }
        }

        private void OnRecordingStopped(object? sender, StoppedEventArgs e)
        {
            if (e.Exception != null)
            {
                LogMessage($"‚ùå –ó–∞–ø–∏—Å—å –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ —Å –æ—à–∏–±–∫–æ–π: {e.Exception.Message}");
            }
        }

        private float CalculateAudioLevel(byte[] buffer, int bytesRecorded)
        {
            if (bytesRecorded == 0) return 0f;

            float sum = 0f;
            int sampleCount = 0;

            // Assuming 32-bit float samples
            for (int i = 0; i < bytesRecorded - 3; i += 4)
            {
                float sample = BitConverter.ToSingle(buffer, i);
                sum += Math.Abs(sample);
                sampleCount++;
            }

            float avgLevel = sampleCount > 0 ? sum / sampleCount : 0f;
            
            // Amplify the level for better visualization (multiply by 10)
            return avgLevel * 10f;
        }

        private void AudioLevelTimer_Tick(object? sender, EventArgs e)
        {
            if (isCapturing)
            {
                int percentage = (int)(currentAudioLevel * 100);
                percentage = Math.Min(100, percentage);
                
                progressAudioLevel.Value = percentage;
                lblAudioLevel.Text = $"üìä –£—Ä–æ–≤–µ–Ω—å: {percentage}%";
                lblAudioLevel.ForeColor = percentage > (voiceThreshold * 100) ? Color.Green : Color.Gray;
            }
        }

        #endregion

        #region STT Processing

        private async Task ProcessAudioAsync(byte[] audioData)
        {
            try
            {
                LogMessage($"üéØ –ù–∞—á–∞–ª–æ STT –æ–±—Ä–∞–±–æ—Ç–∫–∏ ({audioData.Length} –±–∞–π—Ç)");
                
                // Convert to WAV format for Whisper
                var wavData = ConvertToWav(audioData);
                LogMessage($"üîÑ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ WAV: {wavData.Length} –±–∞–π—Ç");

                // Perform STT with Whisper.NET
                string recognizedText = await PerformWhisperSTT(wavData);
                
                if (!string.IsNullOrEmpty(recognizedText) && IsValidSpeech(recognizedText))
                {
                    LogMessage($"‚úÖ –†–∞—Å–ø–æ–∑–Ω–∞–Ω —Ç–µ–∫—Å—Ç: '{recognizedText}'");
                    
                    Invoke(() => {
                        txtRecognizedText.Text = recognizedText;
                        progressBar.Visible = false;
                    });

                    // Auto-translate if enabled
                    if (chkAutoTranslate.Checked)
                    {
                        await TranslateAndSpeak(recognizedText);
                    }
                }
                else
                {
                    LogMessage("‚ö†Ô∏è –¢–µ–∫—Å—Ç –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω –∏–ª–∏ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω –∫–∞–∫ –∑–∞–≥–ª—É—à–∫–∞");
                    Invoke(() => {
                        txtRecognizedText.Text = "‚ùå –¢–µ–∫—Å—Ç –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω";
                        progressBar.Visible = false;
                    });
                }
                
                // Reset capture state for continuous listening
                isCollectingAudio = false;
                audioBuffer.Clear();
            }
            catch (Exception ex)
            {
                LogMessage($"‚ùå –û—à–∏–±–∫–∞ STT –æ–±—Ä–∞–±–æ—Ç–∫–∏: {ex.Message}");
                Invoke(() => {
                    txtRecognizedText.Text = $"‚ùå –û—à–∏–±–∫–∞: {ex.Message}";
                    progressBar.Visible = false;
                });
                
                // Reset capture state even on error
                isCollectingAudio = false;
                audioBuffer.Clear();
            }
        }

        private async Task<string> PerformWhisperSTT(byte[] wavData)
        {
            try
            {
                LogMessage("ü§ñ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Whisper.NET...");
                
                // Create temporary WAV file
                string tempFile = Path.GetTempFileName();
                await File.WriteAllBytesAsync(tempFile, wavData);
                
                try
                {
                    using var whisperFactory = WhisperFactory.FromPath(WhisperModelPath);
                    using var processor = whisperFactory.CreateBuilder()
                        .WithLanguage("auto") // –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —è–∑—ã–∫–∞
                        .WithPrompt("This is human speech") // –§–æ–∫—É—Å –Ω–∞ —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–π —Ä–µ—á–∏
                        .WithProbabilities() // –í–∫–ª—é—á–∞–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
                        .WithTemperature(0.0f) // –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
                        .Build();

                    LogMessage("üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ —á–µ—Ä–µ–∑ Whisper...");
                    
                    using var fileStream = File.OpenRead(tempFile);
                    var result = new StringBuilder();
                    
                    await foreach (var segment in processor.ProcessAsync(fileStream))
                    {
                        LogMessage($"üéØ Whisper —Å–µ–≥–º–µ–Ω—Ç: '{segment.Text}'");
                        
                        if (!string.IsNullOrWhiteSpace(segment.Text))
                        {
                            string cleanText = segment.Text.Trim();
                            
                            // –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –∑–∞–≥–ª—É—à–∫–∏ –ø–µ—Ä–µ–¥ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ–º
                            if (!IsPlaceholderToken(cleanText))
                            {
                                result.Append(cleanText + " ");
                            }
                            else
                            {
                                LogMessage($"üö´ –ü—Ä–æ–ø—É—â–µ–Ω —Å–µ–≥–º–µ–Ω—Ç-–∑–∞–≥–ª—É—à–∫–∞: '{cleanText}'");
                            }
                        }
                    }
                    
                    return result.ToString().Trim();
                }
                finally
                {
                    // Clean up temp file
                    try { File.Delete(tempFile); } catch { }
                }
            }
            catch (Exception ex)
            {
                LogMessage($"‚ùå –û—à–∏–±–∫–∞ Whisper.NET: {ex.Message}");
                return string.Empty;
            }
        }

        private bool IsValidSpeech(string text)
        {
            if (string.IsNullOrWhiteSpace(text)) return false;
            
            string cleanText = text.Trim().ToLower();
            
            // Filter out Whisper placeholders and tokens
            string[] invalidTokens = {
                "[", "]", "(", ")",
                "wheat", "subscribe", "music", "applause", "nice move", "stack", "tablet", "drums",
                "–ø—à–µ–Ω–∏—Ü–∞", "–ø–æ–¥–ø–∏—Å–∞—Ç—å—Å—è", "–º—É–∑—ã–∫–∞", "–∞–ø–ª–æ–¥–∏—Å–º–µ–Ω—Ç—ã",
                "thank you", "—Å–ø–∞—Å–∏–±–æ", "thanks", "bye", "–ø–æ–∫–∞"
            };
            
            // Check for repetitive patterns (same phrase repeated multiple times)
            string[] words = cleanText.Split(' ', StringSplitOptions.RemoveEmptyEntries);
            if (words.Length > 9) // More than 3 words repeated 3 times
            {
                var wordGroups = new Dictionary<string, int>();
                for (int i = 0; i < words.Length - 2; i++)
                {
                    string trigram = $"{words[i]} {words[i + 1]} {words[i + 2]}";
                    if (wordGroups.ContainsKey(trigram))
                        wordGroups[trigram]++;
                    else
                        wordGroups[trigram] = 1;
                }
                
                var mostRepeated = wordGroups.Where(kv => kv.Value >= 3).FirstOrDefault();
                if (mostRepeated.Value >= 3)
                {
                    LogMessage($"üö´ –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω –∫–∞–∫ –ø–æ–≤—Ç–æ—Ä—è—é—â–∞—è—Å—è –∑–∞–≥–ª—É—à–∫–∞: '{mostRepeated.Key}' –ø–æ–≤—Ç–æ—Ä—è–µ—Ç—Å—è {mostRepeated.Value} —Ä–∞–∑");
                    return false;
                }
            }
            
            foreach (string token in invalidTokens)
            {
                if (cleanText.Contains(token.ToLower()))
                {
                    LogMessage($"üö´ –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω –∫–∞–∫ –∑–∞–≥–ª—É—à–∫–∞: '{text}' (—Å–æ–¥–µ—Ä–∂–∏—Ç '{token}')");
                    return false;
                }
            }
            
            // Must be at least 3 characters and contain letters
            if (cleanText.Length < 3 || !cleanText.Any(char.IsLetter))
            {
                LogMessage($"üö´ –°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π –∏–ª–∏ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –±—É–∫–≤: '{text}'");
                return false;
            }
            
            return true;
        }

        private bool IsPlaceholderToken(string text)
        {
            if (string.IsNullOrWhiteSpace(text)) return true;
            
            string cleanText = text.Trim().ToLower();
            
            // –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤
            string[] singleTokens = {
                "[music]", "[drums]", "[distorted breathing]", "[drum roll]", "[dark music]", "[distorted sound]",
                "[applause]", "[laughter]", "[beep]", "[click]", "[noise]", "[silence]",
                "music", "drums", "applause", "laughter", "beep", "click", "noise", "silence"
            };
            
            foreach (string token in singleTokens)
            {
                if (cleanText.Equals(token))
                {
                    return true;
                }
            }
            
            // –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ —Å–∫–æ–±–æ–∫
            if (cleanText.Contains("[") || cleanText.Contains("("))
            {
                return true;
            }
            
            return false;
        }

        private byte[] ConvertToWav(byte[] audioData)
        {
            try
            {
                // –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ 32-bit float 44100Hz mono
                // Whisper.NET —Ç—Ä–µ–±—É–µ—Ç 16kHz 16-bit mono WAV
                
                const int targetSampleRate = 16000;
                const int sourceSampleRate = 44100; // –ò—Å—Ö–æ–¥–Ω–∞—è —á–∞—Å—Ç–æ—Ç–∞ WASAPI
                const int channels = 1;
                const int bitsPerSample = 16;
                
                // –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º float32 –≤ int16 —Å —Ä–µ—Å–∞–º–ø–ª–∏–Ω–≥–æ–º
                var samples = new List<short>();
                
                // –ü—Ä–æ—Å—Ç–æ–π downsampling: –±–µ—Ä–µ–º –∫–∞–∂–¥—ã–π (44100/16000) ‚âà 2.75-–π —Å–µ–º–ø–ª
                float ratio = (float)sourceSampleRate / targetSampleRate;
                
                for (int i = 0; i < audioData.Length - 3; i += 4)
                {
                    float floatSample = BitConverter.ToSingle(audioData, i);
                    
                    // –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ 16-bit
                    floatSample = Math.Max(-1.0f, Math.Min(1.0f, floatSample));
                    short intSample = (short)(floatSample * 32767f);
                    
                    // –ü—Ä–∏–º–µ–Ω—è–µ–º –ø—Ä–æ—Å—Ç–æ–π downsampling
                    if (samples.Count < (i / 4) / ratio)
                    {
                        samples.Add(intSample);
                    }
                }
                
                // –°–æ–∑–¥–∞–µ–º WAV —Ñ–∞–π–ª —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –∑–∞–≥–æ–ª–æ–≤–∫–æ–º
                var wav = new List<byte>();
                
                // RIFF header
                wav.AddRange(Encoding.ASCII.GetBytes("RIFF"));
                wav.AddRange(BitConverter.GetBytes(36 + samples.Count * 2)); // File size - 8
                wav.AddRange(Encoding.ASCII.GetBytes("WAVE"));
                
                // fmt chunk
                wav.AddRange(Encoding.ASCII.GetBytes("fmt "));
                wav.AddRange(BitConverter.GetBytes(16)); // PCM chunk size
                wav.AddRange(BitConverter.GetBytes((short)1)); // PCM format
                wav.AddRange(BitConverter.GetBytes((short)channels)); // Mono
                wav.AddRange(BitConverter.GetBytes(targetSampleRate)); // 16kHz
                wav.AddRange(BitConverter.GetBytes(targetSampleRate * channels * bitsPerSample / 8)); // Byte rate
                wav.AddRange(BitConverter.GetBytes((short)(channels * bitsPerSample / 8))); // Block align
                wav.AddRange(BitConverter.GetBytes((short)bitsPerSample)); // 16-bit
                
                // data chunk
                wav.AddRange(Encoding.ASCII.GetBytes("data"));
                wav.AddRange(BitConverter.GetBytes(samples.Count * 2)); // Data size
                
                // Audio data
                foreach (var sample in samples)
                {
                    wav.AddRange(BitConverter.GetBytes(sample));
                }
                
                return wav.ToArray();
            }
            catch (Exception ex)
            {
                LogMessage($"‚ùå –û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ WAV: {ex.Message}");
                return audioData; // Fallback: –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            }
        }

        #endregion

        #region Translation & TTS

        private async Task TranslateAndSpeak(string text)
        {
            try
            {
                string sourceLang = GetLanguageCode(cbSourceLang.SelectedItem?.ToString() ?? "–ê–Ω–≥–ª–∏–π—Å–∫–∏–π");
                string targetLang = GetLanguageCode(cbTargetLang.SelectedItem?.ToString() ?? "–†—É—Å—Å–∫–∏–π");
                
                LogMessage($"üåê –ü–µ—Ä–µ–≤–æ–¥: {sourceLang} ‚Üí {targetLang}");
                
                Invoke(() => {
                    txtTranslatedText.Text = "üîÑ –ü–µ—Ä–µ–≤–æ–¥–∏–º...";
                });
                
                string translatedText = await TranslateText(text, sourceLang, targetLang);
                
                if (!string.IsNullOrEmpty(translatedText))
                {
                    LogMessage($"‚úÖ –ü–µ—Ä–µ–≤–µ–¥–µ–Ω–æ: '{translatedText}'");
                    
                    Invoke(() => {
                        txtTranslatedText.Text = translatedText;
                    });
                    
                    // Speak translated text
                    await SpeakText(translatedText);
                }
                else
                {
                    LogMessage("‚ùå –ü–µ—Ä–µ–≤–æ–¥ –Ω–µ —É–¥–∞–ª—Å—è");
                    Invoke(() => {
                        txtTranslatedText.Text = "‚ùå –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞";
                    });
                }
            }
            catch (Exception ex)
            {
                LogMessage($"‚ùå –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞: {ex.Message}");
                Invoke(() => {
                    txtTranslatedText.Text = $"‚ùå –û—à–∏–±–∫–∞: {ex.Message}";
                });
            }
        }

        private async Task<string> TranslateText(string text, string sourceLang, string targetLang)
        {
            try
            {
                if (googleTranslateClient == null) return string.Empty;
                
                // Use Google Translate API (public endpoint)
                var request = new RestRequest("translate_a/single", Method.Get);
                request.AddParameter("client", "gtx");
                request.AddParameter("sl", sourceLang);
                request.AddParameter("tl", targetLang);
                request.AddParameter("dt", "t");
                request.AddParameter("q", text);
                request.AddParameter("ie", "UTF-8");
                request.AddParameter("oe", "UTF-8");
                
                var response = await googleTranslateClient.ExecuteAsync(request);
                
                if (response.IsSuccessful && !string.IsNullOrEmpty(response.Content))
                {
                    LogMessage($"üîç Google Translate –æ—Ç–≤–µ—Ç: {response.Content.Substring(0, Math.Min(200, response.Content.Length))}...");
                    
                    // Parse Google Translate response - –±–æ–ª–µ–µ –±–µ–∑–æ–ø–∞—Å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥
                    try
                    {
                        // Google –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–∞—Å—Å–∏–≤ –º–∞—Å—Å–∏–≤–æ–≤, –≥–¥–µ [0][0][0] —ç—Ç–æ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
                        var jsonArray = JsonConvert.DeserializeObject<dynamic>(response.Content);
                        
                        if (jsonArray is Newtonsoft.Json.Linq.JArray outerArray && outerArray.Count > 0)
                        {
                            var firstGroup = outerArray[0];
                            if (firstGroup is Newtonsoft.Json.Linq.JArray firstArray && firstArray.Count > 0)
                            {
                                var firstTranslation = firstArray[0];
                                if (firstTranslation is Newtonsoft.Json.Linq.JArray translationArray && translationArray.Count > 0)
                                {
                                    string translatedText = translationArray[0]?.ToString() ?? "";
                                    if (!string.IsNullOrEmpty(translatedText))
                                    {
                                        LogMessage($"‚úÖ –£—Å–ø–µ—à–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –ø–µ—Ä–µ–≤–æ–¥–∞: '{translatedText}'");
                                        return translatedText;
                                    }
                                }
                            }
                        }
                        
                        LogMessage("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –ø–µ—Ä–µ–≤–æ–¥ –∏–∑ JSON –æ—Ç–≤–µ—Ç–∞");
                        return string.Empty;
                    }
                    catch (JsonException jsonEx)
                    {
                        LogMessage($"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {jsonEx.Message}");
                        
                        // Fallback: –ø–æ–ø—ã—Ç–∫–∞ –ø—Ä–æ—Å—Ç–æ–≥–æ regex –ø–∞—Ä—Å–∏–Ω–≥–∞
                        var match = System.Text.RegularExpressions.Regex.Match(response.Content, @"\[\[\[""([^""]+)""");
                        if (match.Success && match.Groups.Count > 1)
                        {
                            string simpleResult = match.Groups[1].Value;
                            LogMessage($"‚úÖ Fallback –ø–∞—Ä—Å–∏–Ω–≥ —É—Å–ø–µ—à–µ–Ω: '{simpleResult}'");
                            return simpleResult;
                        }
                        
                        return string.Empty;
                    }
                }
                
                LogMessage($"‚ùå –ü–µ—Ä–µ–≤–æ–¥ –Ω–µ —É–¥–∞–ª—Å—è: {response.ErrorMessage ?? "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞"}, StatusCode: {response.StatusCode}");
                return string.Empty;
            }
            catch (Exception ex)
            {
                LogMessage($"‚ùå –û—à–∏–±–∫–∞ API –ø–µ—Ä–µ–≤–æ–¥–∞: {ex.Message}");
                return string.Empty;
            }
        }

        private async Task SpeakText(string text)
        {
            try
            {
                if (speechSynthesizer == null) return;
                
                LogMessage($"üîä –û–∑–≤—É—á–∏–≤–∞–Ω–∏–µ: '{text}'");
                
                await Task.Run(() => {
                    speechSynthesizer.SpeakAsync(text);
                });
                
                LogMessage("‚úÖ –û–∑–≤—É—á–∏–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ");
            }
            catch (Exception ex)
            {
                LogMessage($"‚ùå –û—à–∏–±–∫–∞ –æ–∑–≤—É—á–∏–≤–∞–Ω–∏—è: {ex.Message}");
            }
        }

        private string GetLanguageCode(string languageName)
        {
            return languageCodes.TryGetValue(languageName, out string? code) ? code : "en";
        }

        #endregion

        #region UI Events

        private async void btnTestTTS_Click(object sender, EventArgs e)
        {
            string testText = cbTargetLang.SelectedItem?.ToString() == "–†—É—Å—Å–∫–∏–π" 
                ? "–¢–µ—Å—Ç —Å–∏—Å—Ç–µ–º—ã –æ–∑–≤—É—á–∏–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞" 
                : "Text to speech system test";
                
            await SpeakText(testText);
        }

        private void Form1_FormClosing(object sender, FormClosingEventArgs e)
        {
            StopAudioCapture();
            speechSynthesizer?.Dispose();
            audioLevelTimer?.Dispose();
        }

        #endregion

        #region Logging

        private void LogMessage(string message)
        {
            string timestamp = DateTime.Now.ToString("HH:mm:ss.fff");
            string logEntry = $"[{timestamp}] {message}";
            
            Debug.WriteLine(logEntry);
            
            if (InvokeRequired)
            {
                Invoke(() => AddLogEntry(logEntry));
            }
            else
            {
                AddLogEntry(logEntry);
            }
        }

        private void AddLogEntry(string logEntry)
        {
            txtLogs.AppendText(logEntry + Environment.NewLine);
            txtLogs.SelectionStart = txtLogs.Text.Length;
            txtLogs.ScrollToCaret();
        }

        #endregion

        #region Helper Classes

        private class AudioDevice
        {
            public string Name { get; set; } = string.Empty;
            public MMDevice Device { get; set; } = null!;
            
            public override string ToString() => Name;
        }

        #endregion
    }
}
